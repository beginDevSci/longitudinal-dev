---
title: "LMM with Time Invariant Covariates"
author: "Biostatistics Working Group"
---

## <span class="text-green-500 text-4xl font-extrabold text-transparent">Introduction</span>

### <span class="text-green-500 text-xl font-extrabold text-transparent">Overview</span>

A **linear mixed model (LMM)** is a statistical approach used in longitudinal data analysis to account for both **fixed effects** (population-level trends) and **random effects** (individual variation). 

Unlike traditional linear regression, LMMs allow for **random intercepts** (individual differences in baseline values) and **random slopes** (individual differences in rate of change over time). This makes LMM particularly useful for **modeling repeated measures** where observations are nested within individuals.

### <span class="text-green-500 text-xl font-extrabold text-transparent">Objectives</span>

- **Fit** an LMM with random intercepts and slopes 
- **Analyze** repeated measurement (4 bi-annual assessments) of scores on a measure of cognition.
- **Characterize** individual differences in neurocognitive change over time**
- **Examine** the effect of time-invariant covariates (e.g., parental education) on cognitive development.
- **Discuss** limitations and alternative approaches for varying contexts.

### <span class="text-green-500 text-xl font-extrabold text-transparent">When to Use This Approach</span>

- When **repeated measures** are collected from the same individuals.
- When individual differences in **both baseline values (intercepts) and change over time (slopes)** are expected.
- When accounting for **time-invariant (e.g., parental education) and time-varying (e.g., age) predictors**.

### <span class="text-green-500 text-xl font-extrabold text-transparent">Limitations & Alternatives</span>

- If **random slopes are not needed**, a **random intercept-only model** may be preferable.
- If **correlation between measurements is unknown**, **Generalized Estimating Equations (GEE)** could be considered.
- If modeling **latent change processes**, **Structural Equation Modeling (SEM)** may be a better choice.

<hr border="2" style="border-color: green;">

## <span class="text-4xl text-green-500 font-black">Data Loading & Preparation</span>

::tabs

::tab{label="Load Data" icon="i-heroicons-document-text"}

> This code loads libraries, reads in data from Parquet file(s), filters relevant sessions, processes variables, renames columns, sorts data, and removes missing values.

<details open>
  <summary>✅ <span class="text-l text-green-500">Load Libraries</span></summary>
Load all required R packages for data processing, visualization, and modeling.

```r [LoadLibraries.r]
# 📌 Load necessary libraries
library(arrow)       # For reading Parquet files (efficient storage format)
library(tidyverse)   # For data manipulation & visualization
library(gtsummary)   # For generating publication-quality summary tables
library(rstatix)     # Provides tidy-format statistical tests
library(lme4)        # Linear mixed-effects models (LMMs)
library(kableExtra)  # Formatting & styling in HTML/Markdown reports
library(performance) # Useful functions for model diagnostics & comparisons
```
</details>

<details>
  <summary>✅  <span class="text-l text-green-500">Load the Raw Data</span> </summary>
Load data from a Parquet file and selects relevant variables.

```r [LoadData.r]
# 📌 Define file paths (Update as needed)
ab_file <- "/Users/shawes/ABCD/data/release6/ABCD_General/ABCD_General.parquet"
nc_file <- "/Users/shawes/ABCD/data/release6/Neurocognition/Neurocognition.parquet"

# 📌 Load relevant variables from the Parquet file
ab_data <- read_parquet(ab_file, col_select = c("participant_id", "session_id", "ab_p_demo__ed__slf_001"))
nc_data <- read_parquet(nc_file, col_select = c("participant_id", "session_id", "nc_y_nihtb__comp__cryst__fullcorr_tscore"))

# Merge datasets and prepare for analysis
combined_data <- inner_join(ab_data, nc_data, by = c("participant_id", "session_id"))

```
</details>

<details>
  <summary>✅ <span class="text-l text-green-500">Prepare Data for LMM Analysis</span></summary>
Clean and transform the data.

```r [PrepareData.r]
# 📌 Prepare data for LMM analysis
df_long <- combined_data %>%
  select(participant_id, session_id, ab_p_demo__ed__slf_001, nc_y_nihtb__comp__cryst__fullcorr_tscore) %>%
    # 📌 Filter to include only 4 relevant measurement occasions
    filter(session_id %in% c("ses-00A", "ses-02A", "ses-04A", "ses-06A")) %>%
    # 📌 Ensure dataset is sorted by participant and session
    arrange(participant_id, session_id) %>%
    # 📌 Convert categorical and numerical variables
    mutate(
        participant_id = factor(participant_id), # Convert IDs to factors
        session_id = factor(session_id, # Convert session to factors
            levels = c("ses-00A", "ses-02A", "ses-04A", "ses-06A"),
            labels = c("Baseline", "Year_2", "Year_4", "Year_6")
        ),
        time = as.numeric(session_id) - 1, # Convert session_id to numeric
        nc_y_nihtb__comp__cryst__fullcorr_tscore =
            round(as.numeric(nc_y_nihtb__comp__cryst__fullcorr_tscore), 2),
         
        # 📌 Convert and clean parent education variable
        parent_education = as.numeric(ab_p_demo__ed__slf_001),
        parent_education = na_if(parent_education, 777),  # Set "Decline to Answer" as NA
    ) %>%
    # 📌 Fill missing parent education values with baseline value per participant
    group_by(participant_id) %>%
    mutate(parent_education = first(na.omit(parent_education))) %>%
    ungroup() %>%
    mutate(
        # 📌 Categorize parent education levels
        parent_education_cat = case_when(
            parent_education <= 12 ~ "Less than HS",
            parent_education %in% 13:14 ~ "HS Diploma/GED",
            parent_education %in% 15:17 ~ "Some College/Associate",
            parent_education == 18 ~ "Bachelor’s Degree",
            parent_education %in% 19:21 ~ "Graduate Degree",
            TRUE ~ NA_character_
        ) %>% factor(levels = c("Less than HS", "HS Diploma/GED", 
                                 "Some College/Associate", "Bachelor’s Degree", "Graduate Degree")),
        
        # 📌 Convert neurocognition score
        neurocognition = round(as.numeric(nc_y_nihtb__comp__cryst__fullcorr_tscore), 2)
    ) %>%
    # 📌 Rename variables for clarity
    rename(
        id = participant_id, 
        session = session_id,
        cognition = nc_y_nihtb__comp__cryst__fullcorr_tscore
    ) %>%
    # 📌 Drop rows with missing values to ensure complete cases in analysis
    drop_na()

```

</details>

::

::tab{label="View Data" icon="i-heroicons-document-text"}

> The code below provides a preview the newly created dataframe.

<details open>
  <summary>✅ <span class="text-l text-green-500">Subset the data</span></summary>
Subset data to be dispalyed and reorder columns for better readability.

```r [Subset.r]
# 📌 Select a small subset of data for preview
df_preview <- df_long %>%
    slice_head(n = 10) %>%  # ✅ Select the first 10 rows for preview
    mutate(Index = row_number()) %>%  # 📌 Create an indexing column
    select(Index, everything(), -id)  # 📌 Move Index to first column
```

</details>

<details>
    <summary>✅ <span class="text-l text-green-500">Format the Table</span></summary>

Format and style the data to be displayed.

```r [htmlTable.r]
# 📌 Generate a nicely formatted HTML table for display
table_output <- df_preview %>%
    kableExtra::kable(
        format = "html",  # Render as an HTML table for RMarkdown/Quarto
        digits = 3,  # Round numeric values to 3 decimal places
        booktabs = TRUE,  # Improve table aesthetics
        escape = FALSE,  # Enable HTML styling inside the table
        caption = "**Data View**",  # Add a title to the table
        align = "c"  # Center table content
    ) %>%

    # 📌 Apply Bootstrap-based styling for better readability
    kableExtra::kable_styling(
        full_width = FALSE,  # Prevents table from stretching across the page
        bootstrap_options = c("striped", "hover", "condensed", "responsive"),  # Enable interactive styling
        font_size = 14  # Adjust font size for readability
    ) %>%

    # 📌 Style the header row for better readability
    kableExtra::row_spec(
        row = 0,  # Target the header row
        bold = TRUE,  # Make header text bold
        background = "#f2f2f2"  # Light gray background for better visibility
    )

# ✅ Display the formatted table
table_output

```

<ImageComponent :src="/examples/LMM/ViewData_Table.png" alt="Logo Image" width="800" style="display: block; margin: auto;" />

</ImageComponent>

</details>

::

::tab{label="Descriptives" icon="i-heroicons-document-text"}
> This code generates descriptive and summary statistics for primary variables across assessments.

<details open>
<summary>✅ <span class="text-l text-green-500">Prepare & Transform the Data</span></summary>
  Select relevant variables and convert categorical variables into factors.

```r [Transform.r]
# 📌 Select relevant columns for summary
df_summary <- df_long %>%
    select(session, parent_education_cat, cognition)  # ✅ Select only session and cognition variables

# 📌 Convert 'session' into a factor for proper grouping
df_summary <- df_summary %>%
    mutate(session = factor(session))  # Ensures session is treated as a categorical variable

# ✅ Preview the transformed dataset
head(df_summary)

```

</details>

<details>
    <summary>✅ <span class="text-l text-green-500">Compute Summary Statistics</span></summary>
Create a formatted summary table.

```r [Descriptives.r]
# 📌 Generate a summary table for cognition scores across sessions
descriptives_table <- df_summary %>%
    tbl_summary(
        by = session,  # Group statistics by session
        missing = "no",  # Exclude missing data from summary
        label = list(cognition ~ "Cognition Score", parent_education_cat ~ "Parental Education"),  # Rename cognition column for readability
        statistic = list(
            all_continuous() ~ "{mean} ({sd})"  # Display mean and standard deviation
        )
    )

# ✅ Display the summary table
descriptives_table

```

</details>

<details>
  <summary>✅ <span class="text-l text-green-500">Improve Table Formatting for Readability</span></summary>
Style the summary table.

```r [DescriptivesTable.r]
# 📌 Format table headers for better readability
descriptives_table <- descriptives_table %>%
    modify_header(all_stat_cols() ~ "**{level}**<br>N = {n}") %>%  # Display sample size in column headers
    bold_labels() %>%  # Make variable names bold
    italicize_levels() %>%  # Italicize factor level names
    modify_spanning_header(all_stat_cols() ~ "**Assessment Wave**")  # Add a spanning header

# 📌 Apply compact styling for better visualization
theme_gtsummary_compact()

# ✅ Display the final styled summary table
descriptives_table

```

</details>

<figure class="w-full text-center">

<ImageComponent :src="/examples/LMM/Descriptives_Table.png" alt="Table Output" width="800" style="display: block; margin: auto;" />

</ImageComponent> <figcaption class="text-gray-600 text-sm mt-2">Figure: Descriptive Statistics</figcaption>

</figure>

::
::

<hr border="2" style="border-color: green;">

## <span class="text-green-500 text-4xl font-extrabold text-transparent">Analysis</span>

::tabs

::tab{label="Fit Model" icon="i-heroicons-document-text"}

> Fitting a Random-Intercept and Random-Slope LMM with a time-invariant covariate.

<details open>
    <summary>✅ <span class="text-l text-green-500">Fit Model</span></summary>
Fit a linear mixed model to predict cognition scores over time.

- **Fixed effects:** Intercept, event (time), parental education.
- **Random effects:** Individual differences in intercepts and slopes.

```r [FitModel.r]

# 📌 Fit a Linear Mixed Model (LMM) to predict cognition over time
model_LMM <- lmerTest::lmer(
    cognition ~ time + parent_education + (1 + time | id), # Fixed effect (time), random intercept & slope (id)
    data = df_long # Dataset containing repeated measures of cognition
)
```

</details>

<br>

<details open>
    <summary>✅ <span class="text-l text-green-500">Model Output</span></summary>
Display the model output and summary statistics.

```r [ModelOutput.r]

# 📌 Display summary statistics for the fitted Linear Mixed Model (LMM)
summary(model_LMM)  # Provides estimates for fixed & random effects, along with model diagnostics

# 📌 Compute 95% confidence intervals for model parameters using the Wald method
confint(model_LMM, oldNames = TRUE, method = "Wald")  
# Shows uncertainty around fixed effect estimates, useful for statistical inference

```

<figure class="w-full text-center">

<ImageComponent :src="/examples/LMM/LMM_Output.png" alt="LMM Output" width="800" style="display: block; margin: auto;" />

</ImageComponent> <figcaption class="text-gray-600 text-sm mt-2">Figure: LMM Output</figcaption>

</figure>


        ::card{title="Interpretation" icon="i-heroicons-light-bulb" style="max-width: 800px; margin: auto;"}
        <span style="font-size: 20px;"> 
        - **Intercept**: Baseline neurocognition score.
        - **Event (Time)**: Change over time.
        - **Parental Education**: Effect on cognitive development.
        - **Random Intercepts & Slopes**: Individual variability in baseline and growth rates.
        </span>
        ::


</details>

::

::tab{label="Model Table" icon="i-heroicons-document-text"}

> Generate Publication Quality Table

<details open>
    <summary>✅ <span class="text-l text-green-500">sjPlot Table</span></summary>
Use the sJPlot library to create a publication-quality summary table for the LMM model.

```r [sjPlot.r]

# 📌 Generate a publication-quality summary table for the LMM model
sjPlot::tab_model(model_LMM,
    show.se = TRUE, show.df = FALSE, show.ci = FALSE,
    digits = 3, pred.labels = c("Intercept", "Time"),
    dv.labels = c("LMM Model (lme4)"), string.se = "SE",
    string.p = "P-Value"
)

```

</details>

<figure class="mx-auto text-center bg-white p-4 rounded-lg shadow-md" style="width: 800px;" justify="center">

<ImageComponent :src="/examples/LMM/LMM_Table.png" alt="LMM Table" width="800" style="display: block; margin: auto;" />

</ImageComponent> <figcaption class="text-gray-600 text-sm mt-2">Figure: LMM Table</figcaption>

</figure>

        ::card{title="Interpretation" icon="i-heroicons-light-bulb" style="max-width: 800px; margin: auto;"}
        <span style="font-size: 20px;"> 
        The **fixed effects estimates** indicate that the **average baseline cognition score** is **50.561 (SE = 0.102, p < 0.001)**, with cognition declining by approximately **0.37 points per biannual assessment** (**Time coefficient = -0.366, SE = 0.042, p < 0.001**), confirming a significant negative trajectory over time. **Random effects estimates** highlight substantial individual variability, with the **random intercept variance (τ00 = 90.73)** suggesting significant differences in baseline cognition and the **random slope variance (τ11 = 2.00)** reflecting variability in the rate of cognitive decline. A **negative intercept-slope correlation (ρ01 = -0.28)** indicates that individuals with higher initial cognition tend to experience steeper declines. Model fit statistics show that **72% of the total variance in cognition (ICC = 0.72) is attributable to individual differences**, while the **marginal R² (0.001) and conditional R² (0.722)** suggest that, although **fixed effects alone explain minimal variance (0.1%)**, the **full model explains 72.2%**, reinforcing the importance of accounting for individual variation in cognitive trajectories.
        </span>
        ::

::

::tab{label="Visualization" icon="i-heroicons-document-text"}

> Plot the model-implied trajectories for each individual.

<details open>
    <summary>✅ <span class="text-l text-green-500">Model Predictions and Filtering</span></summary>
Generate predicted cognition scores and plot values of 250 randomly selected participants.

```r [CreateVisualization.r]
# Get predicted neurocognition scores by parental education
preds_edu <- ggpredict(model_lmm, terms = "parent_education")  # Correct function

# Plot
ggplot(preds_edu, aes(x = x, y = predicted)) +
  geom_point(size = 3, color = "darkred") +
  geom_line(group = 1, color = "darkred") +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.2) +
  labs(title = "Effect of Parental Education on Neurocognition",
       x = "Parental Education Level",
       y = "Predicted Neurocognition Score") +
  theme_minimal()

```
</details>

<figure class="mx-auto text-center bg-white p-4 rounded-lg shadow-md" style="width: 800px;" justify="center">

<ImageComponent :src="/examples/LMM/LMM_Trajectories.png" alt="LMM Trajectories" width="800" class="block mx-auto" />

</ImageComponent> <figcaption class="text-gray-600 text-sm mt-2">Figure: LMM Trajectories</figcaption>

</figure>

        ::card{title="Interpretation" icon="i-heroicons-light-bulb" style="max-width: 800px; margin: auto;"}
        <span style="font-size: 20px;">
        The plot illustrates xxxxxx. 
        </span>

</details>
    
::
::

<hr border="2" style="border-color: green;">

## <span class="text-green-500 text-4xl font-extrabold text-transparent">Discussion</span>

1.  <span class="text-green-500 text-4lg font-extrabold text-transparent">Key Findings</span>

- Neurocognition **changes over time**, but the rate differs across individuals.
- **Higher parental education** is associated with better cognitive performance.
- **Individual differences exist** in both starting points and growth rates.
    
2.  <span class="text-green-500 text-4lg font-extrabold text-transparent">Assumptions & Caveats</span>

- Assumes **normally distributed random effects**.
- May be **sensitive to missing data**.
- Alternative models (**GEE, SEM**) may be considered.

3.  <span class="text-green-500 text-4lg font-extrabold text-transparent">Alternative Models</span>  

- **Random Intercept-Only Model** (if slope variability is small).
- **Growth Curve Models** (if curvilinear trends exist).
- **Bayesian Mixed Models** (for complex priors).

4.  <span class="text-green-500 text-4lg font-extrabold text-transparent">Practical Tips</span>  

    -   **Data Inspection**: Always visualize raw trajectories and predicted lines to confirm model assumptions.
    -   **Covariates**: Additional relevant variables can refine the model and explain variation in intercepts/slopes.
    -   **Model Fit**: Compare AIC/ BIC or use likelihood-ratio tests when adding complexity (e.g., random slopes).
    -   **Model Comparison**: Compare models (e.g., random intercept only vs. random slope) via likelihood-ratio tests or AIC/BIC.
    
---

### <span class="text-green-500 text-4lg font-extrabold text-transparent">Conclusion</span>

By employing a **random-intercept and random-slope linear mixed model**, we accounted for both **individual differences in baseline cognitive performance** and **variation in change trajectories over time**. This approach allows for more precise modeling than traditional repeated-measures ANOVA or simple difference scores by capturing subject-specific growth patterns.

The fixed effects suggest that **neurocognition changes over time**, with **higher parental education linked to better cognitive performance**. The inclusion of **random slopes** indicates that **individuals differ not only in their starting points but also in their rates of change**, underscoring the importance of modeling both sources of variability.

This method is particularly well-suited for **developmental research** where participants show **heterogeneous trajectories**, making it a valuable tool for understanding cognitive development, intervention effects, and risk factors over time.

### See also
- [Introduction to Linear Mixed-Effects Models](https://www.google.com/search?q=linear+mixed+effects+models+longitudinal+analysis+r)  
- [The Hitchhiker’s Guide to Longitudinal Models](https://e-m-mccormick.github.io/static/longitudinal-primer/)
- [Mixed Models with R](https://m-clark.github.io/mixed-models-with-R/)
- [The disaggregation of within-person and between-person effects in longitudinal models of change](https://www.annualreviews.org/content/journals/10.1146/annurev.psych.093008.100356)
- [On the unnecessary ubiquity of hierarchical linear modeling.](https://psycnet.apa.org/fulltext/2016-22467-001.html)
